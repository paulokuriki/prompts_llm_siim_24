{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulokuriki/prompts_llm_siim_24/blob/main/LLM_APIs_for_SIIMv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SIIM 2024 Large Language Model API\n",
        "\n",
        "# Learning Objectives\n",
        "\n",
        "At the end of this session, you should be able to:\n",
        "1. Describe what an API is.\n",
        "2. Understand how to use an API\n",
        "3. Use an API to prompt an LLM (ChatGPT, llama3, etc)\n",
        "\n",
        "## Credits\n",
        "\n",
        "Developed by Paulo Kuriki and Felipe Kitamura\n",
        "\n",
        "# Introduction\n",
        "\n",
        "Today, we'll explore a powerful tool that can enhance your workflow: APIs (Application Programming Interfaces). Imagine APIs as hidden menus in online services, allowing programs to access and exchange data. We'll see how APIs can be used to interact with OpenAI, a platform for artificial intelligence, similar to how you might use a radiology information system (RIS) to access patient data.\n",
        "\n",
        "# What is an API?\n",
        "\n",
        "Think of an API like a waiter in a restaurant. You (the program) tell the waiter (the API) what you want (data or functionality) from the kitchen (the online service). The waiter relays your request and brings you what you need. APIs use a specific language to communicate these requests and responses.\n",
        "\n",
        "\n",
        "![](https://media.dev.to/cdn-cgi/image/width=1600,height=900,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Fqvaysugwhd9mge3pxr7j.png)\n",
        "Source: https://dev.to/hackthisfall/what-is-api-explained-in-easy-way-5aih\n",
        "\n",
        "\n",
        "# Benefits of APIs for Radiologists\n",
        "\n",
        "- Automating tasks: Imagine an API summarizing EHR notes, generating impression for reports, and research papers based on your current case.\n",
        "- Enhanced reporting: APIs could automate report generation based on image analysis and findings.\n"
      ],
      "metadata": {
        "id": "kn1hSwHV7tji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's Get Started\n",
        "\n",
        "### PokeAPI\n",
        "\n",
        "Let's use the PokeAPI as a stepping stone to understand APIs. It provides information about everyone's favorite pocket monsters - Pokemon! Here's a simple Python code snippet in a Jupyter Notebook to demonstrate how to access data using an API:"
      ],
      "metadata": {
        "id": "-trURhknAZ_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import requests\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Image, HTML"
      ],
      "metadata": {
        "id": "KC8IpJ8logew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# URL to fetch the list of Pokémon\n",
        "url = \"https://pokeapi.co/api/v2/pokemon\"\n",
        "\n",
        "# Sending a GET request to the API and storing the response in JSON format\n",
        "data = requests.get(url).json()\n",
        "\n",
        "# Extracting the names of the Pokémon from the 'results' key in the JSON response\n",
        "pokemon_names = [result[\"name\"] for result in data['results']]\n",
        "\n",
        "# Printing results\n",
        "print(url)\n",
        "print(pokemon_names)"
      ],
      "metadata": {
        "id": "f49Qiodq_d-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Consuming a REST API\n",
        "\n",
        "REST (Representational State Transfer) is an architectural style used for designing networked applications. RESTful APIs allow different systems to communicate over the HTTP protocol by defining a set of rules and conventions. In REST, resources (data entities) are identified by URIs (Uniform Resource Identifiers) and can be manipulated using standard HTTP methods.\n",
        "\n",
        "An endpoint is a specific URL (unique address in the internet) where an API can be accessed by a client application.\n",
        "\n",
        "For PokeAPI, an endpoint might look like https://pokeapi.co/api/v2/pokemon/{pokemon_name}.\n",
        "\n",
        "## JSON:\n",
        "\n",
        "JSON (JavaScript Object Notation) is a common format for sending and receiving data in RESTful APIs. It is lightweight and easy to parse.\n",
        "\n",
        "Example:\n",
        "```json\n",
        "{\n",
        "  \"results\": [\n",
        "    {\n",
        "      \"name\": \"bulbasaur\",\n",
        "      \"url\": \"https://pokeapi.co/api/v2/pokemon/1/\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"ivysaur\",\n",
        "      \"url\": \"https://pokeapi.co/api/v2/pokemon/2/\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"venusaur\",\n",
        "      \"url\": \"https://pokeapi.co/api/v2/pokemon/3/\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n"
      ],
      "metadata": {
        "id": "BUF_bQjjRQZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pokemon = widgets.Dropdown(options=pokemon_names)\n",
        "output = widgets.Output()\n",
        "\n",
        "# Define a function to handle user selection\n",
        "def pokemon_selected(change):\n",
        "  # Get the selected Pokemon name\n",
        "  selected_pokemon = change['new']\n",
        "\n",
        "  # Construct the URL for the selected Pokemon\n",
        "  url = f\"https://pokeapi.co/api/v2/pokemon/{selected_pokemon}\"\n",
        "\n",
        "  # Get Pokemon data and display information\n",
        "  data = requests.get(url).json()\n",
        "\n",
        "  output.clear_output()\n",
        "\n",
        "  with output:\n",
        "    print(f\"URL: {url}\")\n",
        "    print(f\"Name: {data['name']}\")\n",
        "    print(f\"Type: {data['types'][0]['type']['name']}\")\n",
        "    print(f\"Height: {data['height']} (decimeters)\")\n",
        "\n",
        "    # Get and display image\n",
        "    image_url = data['sprites']['front_default']\n",
        "    display(Image(url=image_url))\n",
        "\n",
        "# Connect the dropdown selection to the function\n",
        "pokemon.observe(pokemon_selected, names='value')\n",
        "\n",
        "display(pokemon, output)"
      ],
      "metadata": {
        "id": "RV3wE7FDCl3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Many (most) APIs require keys for access\n",
        "\n",
        "APIs, or Application Programming Interfaces, often require the use of access keys to ensure secure and controlled usage. These keys, also known as API keys, serve several critical purposes:\n",
        "\n",
        "- **Authentication and Authorization:** API keys authenticate the user making the request and ensure that only authorized users can access the API. Each key is unique to a user or application, allowing the API provider to control and monitor access.\n",
        "- **Usage Monitoring and Rate Limiting:** By assigning API keys to users, providers can track how the API is used. This monitoring helps enforce rate limits, preventing abuse and ensuring fair use among all users. Rate limits restrict the number of API requests a user can make within a specified time frame.\n",
        "- **Access Control and Permissions:** API keys can be configured to grant different levels of access. For example, some keys may allow read-only access, while others permit read-write operations. This granular control helps in managing different use cases and user roles.\n",
        "- **Billing and Quotas:** Many API providers offer tiered pricing models based on usage. API keys help in tracking usage for billing purposes, ensuring that users are charged appropriately based on their consumption of the API services.\n",
        "\n",
        "### Example Use Case\n",
        "Consider a movie API that provides information on popular movies. To access this API, a developer must sign up and obtain an API key. When making a request to the API, the developer includes the key in the request header or as a URL parameter. The API server then verifies the key, checks the user’s permissions, and processes the request accordingly.\n",
        "\n",
        "[The Movie Database (TMDb)](https://www.themoviedb.org/movie)\n",
        "\n",
        "Below is an example demonstrating how to use an API key to retrieve and display information about popular movies from The Movie Database (TMDb) API.\n",
        "\n",
        "Use this API key: b9e06df8fe4c79bbf2f1f91d1277e1fa"
      ],
      "metadata": {
        "id": "RKOuoPBsOysz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Image, HTML\n",
        "\n",
        "# api_key = 'b9e06df8fe4c79bbf2f1f91d1277e1fa'\n",
        "api_key = 'b9e06df8fe4c79bbf2f1f91d1277e1fa' # @param {type:\"string\"}\n",
        "\n",
        "movies_output = widgets.Output()\n",
        "\n",
        "# Fetch the list of top movies and keep it in memory\n",
        "webpage = 'https://www.themoviedb.org/movie'\n",
        "url = f\"https://api.themoviedb.org/3/movie/popular?api_key={api_key}&language=en-US&page=1\"\n",
        "response = requests.get(url)\n",
        "data = response.json()\n",
        "print(url)\n",
        "if response.status_code != 200:\n",
        "    print(f\"Error fetching data from themoviedb.org. Error {data['status_message']}\")\n",
        "else:\n",
        "    # Extract relevant movie information and store in a dictionary\n",
        "    print(webpage)\n",
        "    movies = {}\n",
        "    for idx, movie in enumerate(data['results'][:10], start=1):  # Get top 10 movies\n",
        "        movies[f\"{idx}. {movie['title']} (Score: {int(movie['vote_average']*10)}%)\"] = movie\n",
        "\n",
        "    # Create a dropdown populated with movie titles, ranks, and user scores\n",
        "    movie_dropdown = widgets.Dropdown(\n",
        "        options=movies.keys(),\n",
        "        description=\"Movies:\",\n",
        "        style={'description_width': 'initial'},\n",
        "        layout=widgets.Layout(width='600px')  # Increase width of the dropdown\n",
        "    )\n",
        "\n",
        "    def display_movie_details(change):\n",
        "        selected_movie = movies[change['new']]\n",
        "\n",
        "        movies_output.clear_output()\n",
        "\n",
        "        with movies_output:\n",
        "            print(f\"Title: {selected_movie['title']}\")\n",
        "            print(f\"Release Date: {selected_movie['release_date']}\")\n",
        "            print(f\"Overview: {selected_movie['overview']}\")\n",
        "            print(f\"User Score: {int(selected_movie['vote_average']*10)}%\")\n",
        "            image_url = f\"https://image.tmdb.org/t/p/w500{selected_movie['poster_path']}\"\n",
        "            display(Image(url=image_url, width=200))\n",
        "\n",
        "    movie_dropdown.observe(display_movie_details, names='value')\n",
        "\n",
        "    # Manually trigger the function to display details of the first movie initially\n",
        "    initial_movie_key = list(movies.keys())[0]\n",
        "    display_movie_details({'new': initial_movie_key})\n",
        "\n",
        "    display(movie_dropdown, movies_output)\n"
      ],
      "metadata": {
        "id": "D2_9VRVaoSzE",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accessing LLMs via APIs for Radiologists\n",
        "Large Language Models (LLMs) can be accessed via APIs to facilitate various tasks in medical practice, particularly for radiologists. These models, provided by services like OpenAI, can assist in interpreting medical images, generating reports, and even providing decision support based on vast amounts of medical literature and data.\n",
        "\n",
        "**Benefits of Using LLMs in Radiology:**\n",
        "- **Automated Report Generation:** LLMs can help radiologists by generating initial drafts of radiology reports based on the findings from imaging studies. This can save time and reduce the cognitive load on radiologists.\n",
        "- **Report Classification:** LLMs can assist in automatically classifying radiology reports into various categories such as normal, abnormal, follow-up required, or urgent. This can help streamline the workflow, prioritize cases needing immediate attention, and organize reports for easier retrieval and analysis.\n",
        "- **Decision Support:** By leveraging LLMs, radiologists can access evidence-based suggestions and differential diagnoses, improving diagnostic accuracy.\n",
        "- **Patient Communication:** LLMs can generate simplified explanations of radiological findings that can be shared with patients, enhancing patient understanding and satisfaction.\n",
        "- **Research and Education:** LLMs can assist in academic research by summarizing the latest studies, providing insights from a large corpus of medical literature, and aiding in continuous medical education.\n",
        "\n",
        "**Example Use Case: Classifing Chest X-Ray Reports**\n",
        "\n"
      ],
      "metadata": {
        "id": "y2_MS6TqRzHa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading necessary libraries"
      ],
      "metadata": {
        "id": "6ZNHf8K_ajGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain langchain_community openai langchain_openai"
      ],
      "metadata": {
        "id": "rD3g_bKsxOdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloading the Dataset\n",
        "\n",
        "```Source: Demner-Fushman D, Kohli MD, Rosenman MB, Shooshan SE, Rodriguez L, Antani S, Thoma GR, McDonald CJ. Preparing a collection of radiology examinations for distribution and retrieval. J Am Med Inform Assoc. 2016 Mar;23(2):304-10. doi: 10.1093/jamia/ocv080. Epub 2015 Jul 1.```"
      ],
      "metadata": {
        "id": "vQbiLRcAanjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# URL to the CSV file\n",
        "url = \"https://raw.githubusercontent.com/paulokuriki/api_for_rads/main/reports.csv\"\n",
        "\n",
        "# Download and read the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Removing empty reports\n",
        "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x).replace('', pd.NA).dropna().reset_index(drop=True)\n",
        "print(f'Total Reports: {len(df)}')\n",
        "\n",
        "# Group by 'label' and calculate size\n",
        "label_counts = df.groupby('label').size()\n",
        "\n",
        "# Calculate percentages\n",
        "percentages = label_counts / label_counts.sum() * 100\n",
        "\n",
        "# Plotting the pie chart\n",
        "plt.figure(figsize=(10, 7))\n",
        "label_counts.plot.pie(autopct='%1.2f%%', colors=sns.color_palette('Dark2'))\n",
        "plt.ylabel('')  # Hide the y-label\n",
        "\n",
        "# Display the first 10 rows of the DataFrame\n",
        "display(df.head(10))\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PPR-W_0wN9ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating our Prompt Template"
      ],
      "metadata": {
        "id": "pNPJYSjZbUSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import OpenAI\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "# Define the prompt template for classification\n",
        "template = \"\"\"\n",
        "### INSTRUCTION\n",
        "You are a specialist in chest x-ray reports. Your task is to classify if a report is normal or abnormal\n",
        "Your response should be in a JSON format with the key \"classification\" and the possible values: \"normal\" or \"abnormal\"\n",
        "\n",
        "### REPORT TO CLASSIFY\n",
        "{report}\n",
        "\"\"\"\n",
        "\n",
        "def get_report_and_label(report_number):\n",
        "    # Extract the chosen report and its label from the DataFrame\n",
        "    report = df.iloc[report_number]['report']\n",
        "    label = df.iloc[report_number]['label']\n",
        "    return report, label\n",
        "\n",
        "def build_prompt(template, report):\n",
        "    # Format the prompt using the provided template and report\n",
        "    formatted_prompt = template.format(report=report)\n",
        "    return formatted_prompt\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "random.seed(50)\n",
        "# Choose a random report index from the dataset\n",
        "random_number = random.randint(0, len(df) - 1)  # Ensure the random index is within range\n",
        "\n",
        "# Get the report and label for the chosen random index\n",
        "report, label = get_report_and_label(random_number)\n",
        "\n",
        "# Build the prompt using the template and the chosen report\n",
        "prompt = build_prompt(template, report)\n",
        "\n",
        "# Display the chosen report and its label\n",
        "print(f\"REPORT #: {random_number}\")\n",
        "print()\n",
        "print('REPORT:')\n",
        "display(report)\n",
        "print()\n",
        "print('LABEL:')\n",
        "print(label)\n",
        "print('-' * 60)\n",
        "print('PROMPT:')\n",
        "print(prompt)\n"
      ],
      "metadata": {
        "id": "odqXk18zXWYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the API Keys\n",
        "\n",
        "Use the temporary link below to copy your API Keys"
      ],
      "metadata": {
        "id": "z1QJKsv6b6xS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://tinyurl.com/siimkeys\n"
      ],
      "metadata": {
        "id": "Dbagg45WvCRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "ENVS = [\"OPENAI_API_KEY\", \"OLLAMA_BASE_URL\"]\n",
        "all_set = True\n",
        "\n",
        "for env in ENVS:\n",
        "    value = getpass.getpass(f\"Enter {env}: \")\n",
        "    if value == '':\n",
        "        value = getpass.getpass(f\"Enter {env}: \")\n",
        "    if value != '':\n",
        "        os.environ[env] = value\n",
        "    if len(value) <= 10:\n",
        "        all_set = False\n",
        "\n",
        "if all_set:\n",
        "    print('All variables are correctly set with more than 10 characters.')\n",
        "else:\n",
        "    print('One or more variables may not be set correctly (less than or equal to 10 characters).')\n",
        "\n",
        "selected_number_cases = 5"
      ],
      "metadata": {
        "id": "kx6hsPhHp1ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sending the Prompt to LLM for classification"
      ],
      "metadata": {
        "id": "Gs7pV3IkJ2Cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI as OpenAI\n",
        "from langchain_community.chat_models import ChatAnyscale as Anyscale\n",
        "from langchain_community.chat_models import ChatOllama as Ollama\n",
        "import json\n",
        "import re\n",
        "\n",
        "def classify_report(prompt, model, use_gpu=True):\n",
        "    # Select the appropriate model based on the input model name\n",
        "    if 'gpt' in model:\n",
        "        # Initialize OpenAI model\n",
        "        llm = OpenAI(model=model, temperature=0, seed=42, model_kwargs={\"response_format\": {\"type\": \"json_object\"}})\n",
        "    else:\n",
        "        # Initialize Ollama model\n",
        "        if use_gpu:\n",
        "            llm = Ollama(model='llama3.1', base_url=os.environ[\"OLLAMA_BASE_URL\"], format='json', keep_alive=-1, temperature=0, seed=42, model_kwargs={\"seed\": 42, \"response_format\": {\"type\": \"json_object\"}})\n",
        "        else:\n",
        "            llm = Ollama(model='llama3.1', base_url=os.environ[\"OLLAMA_BASE_URL\"], format='json', keep_alive=-1, temperature=0, seed=42, model_kwargs={\"seed\": 42, \"response_format\": {\"type\": \"json_object\"}}, num_gpu=0)\n",
        "\n",
        "    # Invoke the model with the given prompt\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    try:\n",
        "        # Attempt to parse the response as JSON\n",
        "        dict_response = json.loads(response.content.lower())\n",
        "        predicted_label = dict_response['classification']\n",
        "    except json.JSONDecodeError:\n",
        "        # If JSON parsing fails, try to extract JSON using a regular expression\n",
        "        json_match = re.search(r'\\{\\s*\"classification\":\\s*\"(normal|abnormal)\"\\s*\\}', response.content)\n",
        "        if json_match:\n",
        "            dict_response = json.loads(json_match.group())\n",
        "            predicted_label = dict_response['classification']\n",
        "        else:\n",
        "            print(\"Error: Invalid JSON response\")\n",
        "            return 'Error'\n",
        "    except Exception as e:\n",
        "        # Handle other exceptions and print an error message\n",
        "        print(f\"Error: {e}. {dict_response}\")\n",
        "        return 'Error'\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "model = 'gpt-4o-mini-2024-07-18' # @param ['gpt-4o-mini-2024-07-18', 'gpt-4o-2024-08-06', 'Ollama']\n",
        "print(model)\n",
        "\n",
        "# Build the prompt for the model\n",
        "prompt = build_prompt(template, report)\n",
        "\n",
        "# Classify the report using the selected model\n",
        "predicted_label = classify_report(prompt, model)\n",
        "\n",
        "# Print the original and predicted labels\n",
        "print(f'Original Label.....: {label}')\n",
        "print(f'LLM Predicted Label: {predicted_label}')\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "tx1EXZ-ZUIWj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting Some Random Cases to Measure the LLM Classification"
      ],
      "metadata": {
        "id": "xSEXIQP6cMav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting some random cases to calculate metrics\n",
        "random.seed(15)\n",
        "selected_report_idxs = random.sample(range(len(df)), selected_number_cases)\n",
        "print(selected_report_idxs)"
      ],
      "metadata": {
        "id": "M0Ib_O21_F6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def run_classification(selected_report_idxs, model, use_gpu=True):\n",
        "    # Initialize an empty list to store the results\n",
        "    results = []\n",
        "    # Loop through each selected report index\n",
        "    for idx in tqdm(selected_report_idxs, desc=f\"Classifying Reports with {model}\"):\n",
        "        # Get the report and its original label\n",
        "        report, label = get_report_and_label(idx)\n",
        "        # Build the prompt using the report\n",
        "        prompt = build_prompt(template, report)\n",
        "        # Classify the report using the specified model\n",
        "        predicted_label = classify_report(prompt, model, use_gpu=use_gpu)\n",
        "        # Append the classification results to the results list\n",
        "        results.append({\n",
        "            'report_number': idx,\n",
        "            'report': report,\n",
        "            'original_label': label,\n",
        "            'predicted_label': predicted_label,\n",
        "            'prompt': prompt\n",
        "        })\n",
        "    # Print a sample prompt for verification\n",
        "    print(\"\\n\\nSAMPLE PROMPT:\")\n",
        "    print(prompt)\n",
        "    # Return the classification results\n",
        "    return results\n",
        "\n",
        "def display_statistics(results, compare_with_labels=True):\n",
        "    # Calculate the total number of cases\n",
        "    total_cases = len(results)\n",
        "    # Count the number of correct predictions\n",
        "    correct_predictions = sum(1 for r in results if r['original_label'].lower() == r['predicted_label'].lower())\n",
        "    # Calculate the accuracy percentage\n",
        "    accuracy = correct_predictions / total_cases * 100\n",
        "    # Print the total cases, correct predictions, and accuracy\n",
        "    if compare_with_labels:\n",
        "        print(f\"Total cases: {total_cases}\")\n",
        "        print(f\"Correct predictions: {correct_predictions}\")\n",
        "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "    else:\n",
        "        print(f\"Total cases: {total_cases}\")\n",
        "        # Count the number of each predicted label\n",
        "        label_counts = {}\n",
        "        for r in results:\n",
        "            predicted_label = r['predicted_label'].lower()\n",
        "            if predicted_label in label_counts:\n",
        "                label_counts[predicted_label] += 1\n",
        "            else:\n",
        "                label_counts[predicted_label] = 1\n",
        "        # Print the count of each predicted label\n",
        "        for label, count in label_counts.items():\n",
        "            print(f\"Total {label} cases: {count}\")\n",
        "\n",
        "    # Loop through each result and print the details\n",
        "    for result in results:\n",
        "        print(\"\\nReport #: \", result['report_number'])\n",
        "        if compare_with_labels:\n",
        "            correct = '✅' if result['original_label'].lower() == result['predicted_label'].lower() else '❌'\n",
        "            print(f\"{correct} Original Label: {result['original_label']}, LLM Label: {result['predicted_label']}\")\n",
        "        else:\n",
        "            positive_findings = {'positive', 'present', 'yes', 'true', 'altered', 'enlarged', 'increased', 'abnormal', 'not normal' , 'dilated'}\n",
        "            positive = '✅' if any(label in result['predicted_label'].lower() for label in positive_findings) else '❌'\n",
        "\n",
        "            print(f\"LLM Label: {positive} {result['predicted_label']}\")\n",
        "        print(f\"Report: {result['report']}\")\n",
        "\n",
        "\n",
        "\n",
        "model = 'gpt-4o-mini-2024-07-18' # @param ['gpt-4o-mini-2024-07-18', 'gpt-4o-2024-08-06', 'Ollama']\n",
        "print(model)\n",
        "\n",
        "# Run the classification process for the selected report indices\n",
        "results = run_classification(selected_report_idxs, model=model, use_gpu=True)\n",
        "# Display the classification statistics\n",
        "display_statistics(results)\n"
      ],
      "metadata": {
        "id": "shzyco8aVjsz",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How can we improve our LLM classification?"
      ],
      "metadata": {
        "id": "kJCjyZ-_reSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the current prompt template\n",
        "print('CURRENT TEMPLATE:')\n",
        "print(template)"
      ],
      "metadata": {
        "id": "nnnUUsw49GLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Improving the Prompt Template with more detailed instructions"
      ],
      "metadata": {
        "id": "N_j2-S3aKXKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "### INSTRUCTION\n",
        "You are a specialist in chest x-ray reports. Your task is to classify if a report is normal or abnormal\n",
        "Your response should be in a JSON format with the key \"classification\" and the possible values: \"normal\" or \"abnormal\"\n",
        "\n",
        "### REQUIREMENTS\n",
        "- Carefully read the report provided below.\n",
        "- Evaluate all relevant medical information described in the report. Any mention of pathological abnormalities, whether chronic or acute, past or present, severe or mild, degenerative changes, malformations or granulomatous diseases, should result in a classification of \"abnormal.\"\n",
        "- Changes in lung volumes like hypo or hyperexpansion, postsurgical changes, or the presence of external devices (e.g., tubes, catheters, cardiac monitors, leads, pacemakers) should result in a classification of \"abnormal.\"\n",
        "- The report is anonymized for privacy reasons, which means \"XXXX\" is used in place of certain details. Ignore \"XXXX\" as it is part of the anonymization process and not indicative of any abnormal finding.\n",
        "- Base your classification solely on the information given in the report, without inferring any additional details.\n",
        "\n",
        "### REPORT TO CLASSIFY\n",
        "{report}\n",
        "\"\"\"\n",
        "\n",
        "model = 'gpt-4o-mini-2024-07-18' # @param ['gpt-4o-mini-2024-07-18', 'gpt-4o-2024-08-06', 'Ollama']\n",
        "print(model)\n",
        "\n",
        "# Run the classification process for the selected report indices\n",
        "results = run_classification(selected_report_idxs, model=model, use_gpu=True)\n",
        "# Display the classification statistics\n",
        "display_statistics(results)"
      ],
      "metadata": {
        "id": "Ky3er2su_oAc",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few-Shot Prompts\n",
        "\n",
        "Few-shot prompts refer to a technique in natural language processing (NLP) where a model is given a small number of examples (typically 1 to 5) within the prompt to guide its response. These examples illustrate the desired task or output format, helping the model understand the pattern or context without needing extensive fine-tuning. Few-shot learning leverages the model's pre-existing knowledge and adapts it to perform specific tasks with minimal training data, making it highly effective for scenarios where labeled data is scarce."
      ],
      "metadata": {
        "id": "uz5kiAPuxz4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FEW SHOT PROMPT WITH SAMPLES\n",
        "\n",
        "# Function to collect samples and update the template\n",
        "def collect_samples_and_update_template(df, template, num_samples=10):\n",
        "    # Get normal and abnormal cases\n",
        "    normal_cases = df[df['label'].str.lower() == 'normal'].sample(num_samples)\n",
        "    abnormal_cases = df[df['label'].str.lower() == 'abnormal'].sample(num_samples)\n",
        "\n",
        "    # Create examples sections\n",
        "    normal_examples_section = \"### EXAMPLES OF NORMAL REPORTS\\n\"\n",
        "    abnormal_examples_section = \"### EXAMPLES OF ABNORMAL REPORTS\\n\"\n",
        "\n",
        "    for idx, row in normal_cases.iterrows():\n",
        "        #normal_examples_section += f\"#### Example {idx + 1}\\n\"\n",
        "        normal_examples_section += f\"Normal Report: {row['report']}\\n\"\n",
        "        #normal_examples_section += \"Classification: normal\\n\\n\"\n",
        "\n",
        "    for idx, row in abnormal_cases.iterrows():\n",
        "        #abnormal_examples_section += f\"#### Example {idx + 1}\\n\"\n",
        "        abnormal_examples_section += f\"Abnormal Report: {row['report']}\\n\"\n",
        "        #abnormal_examples_section += \"Classification: abnormal\\n\\n\"\n",
        "\n",
        "    # Update the template\n",
        "    updated_template = template.format(\n",
        "        normal_examples=normal_examples_section,\n",
        "        abnormal_examples=abnormal_examples_section,\n",
        "        report=\"{report}\"  # Placeholder for the final report\n",
        "    )\n",
        "\n",
        "    return updated_template\n",
        "\n",
        "# Define the template\n",
        "template = \"\"\"\n",
        "### INSTRUCTION\n",
        "You are a specialist in chest x-ray reports. Your task is to classify the following radiology report as either \"normal\" or \"abnormal\". Please provide your response in a JSON format with the key \"classification\" and the possible values: \"normal\" or \"abnormal.\"\n",
        "\n",
        "### REQUIREMENTS\n",
        "- Carefully read the report provided below.\n",
        "- The report is anonymized for privacy reasons, which means \"XXXX\" is used in place of certain details. Ignore \"XXXX\" as it is part of the anonymization process and not indicative of any abnormal finding.\n",
        "- Evaluate all relevant medical information described in the report. Any mention of pathological abnormalities, whether chronic or acute, past or present, severe or mild, degenerative or granulomatous disease, changes in lung volumes, or the presence of external devices (e.g., tubes, catheters, cardiac monitors, leads, pacemakers) should result in a classification of \"abnormal.\"\n",
        "- Base your classification solely on the information given in the report, without inferring any additional details.\n",
        "- Use the samples below to understand what should be considered normal and what should be considered abnormal. Use the same logic to make your classification\n",
        "\n",
        "{normal_examples}\n",
        "\n",
        "{abnormal_examples}\n",
        "\n",
        "### REPORT TO CLASSIFY\n",
        "{report}\n",
        "\"\"\"\n",
        "\n",
        "# Update the template with examples\n",
        "template = collect_samples_and_update_template(df, template, num_samples=10)\n",
        "\n",
        "## Format the template to include the report to classify\n",
        "prompt = template.format(report=report)\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "HVMar421AqYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'gpt-4o-mini-2024-07-18' # @param ['gpt-4o-mini-2024-07-18', 'gpt-4o-2024-08-06', 'Ollama']\n",
        "\n",
        "print(model)\n",
        "\n",
        "# Run the classification process for the selected report indices\n",
        "results = run_classification(selected_report_idxs, model=model, use_gpu=True)\n",
        "# Display the classification statistics\n",
        "display_statistics(results)"
      ],
      "metadata": {
        "id": "7Z35dep_gC6a",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a cardiomegaly classifier 💖\n"
      ],
      "metadata": {
        "id": "K8pXjxK2Mawa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "### INSTRUCTION\n",
        "You are a specialist in chest X-ray reports.\n",
        "Your task is to classify a report as positive if it describes signs of cardiomegaly, such as increased heart size, cardiac size, or cardiomediastinal silhouette. Consider the finding positive even if it is mild. If within normal limits, classify as negative.\n",
        "Your response should be in a JSON format with the key 'classification' and the possible values: 'positive' or 'negative' for the presence (positive) or absence (negative) of your classification.\n",
        "\n",
        "### REPORT TO CLASSIFY\n",
        "{report}\n",
        "\"\"\"\n",
        "\n",
        "model = 'gpt-4o-mini-2024-07-18'\n",
        "results = run_classification(selected_report_idxs, model=model, use_gpu=True)\n",
        "display_statistics(results, compare_with_labels=False)"
      ],
      "metadata": {
        "id": "P2jDkNkJIQZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now it's your time to create your classifier\n",
        "\n",
        "Change only this line of code:\n",
        "\n",
        "```Your task is to classify a report as positive if it describes signs of _____```\n",
        "\n",
        "and run the code again\n",
        "\n",
        "---\n",
        "\n",
        "Some examples you can try:\n",
        "\n",
        "**SPINAL DISEASES:**\n",
        "\n",
        "```Your task is to classify a report as positive if it describes signs of scoliosis or other spinal abnormalities.```\n",
        "\n",
        "**COPD DETECTOR:**\n",
        "\n",
        "```Your task is to classify a report as positive if it describes signs of COPD like hyperexpansion, increased lung volume, or increased lung capacity. Consider the finding positive even if it is mild.```\n",
        "\n",
        "**SURGERY DETECTOR:**\n",
        "\n",
        "```Your task is to classify a report as positive if it describes postoperative changes like surgeries, sternotomy, clips, or other procedures.```"
      ],
      "metadata": {
        "id": "jDK3ShD3Soac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task = 'Your task is to classify a report as positive if it describes signs of COPD like hyperexpansion, increased lung volume, or increased lung capacity. Consider the finding positive even if it is mild.' # @param {type:\"string\"}\n",
        "\n",
        "template = \"\"\"\n",
        "### INSTRUCTION\n",
        "You are a specialist in chest X-ray reports.\n",
        "{task}\n",
        "Your response should be in a JSON format with the key 'classification' and the possible values: 'positive' or 'negative' for the presence (positive) or absence (negative) of your classification.\n",
        "\n",
        "### REPORT TO CLASSIFY\n",
        "{report}\n",
        "\"\"\"\n",
        "template = template.format(task=task, report=\"{report}\")\n",
        "\n",
        "model = 'gpt-4o-mini-2024-07-18'\n",
        "results = run_classification(selected_report_idxs, model=model, use_gpu=True)\n",
        "display_statistics(results, compare_with_labels=False)"
      ],
      "metadata": {
        "id": "X3-FZn3cN-1u",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running Ollama Locally\n",
        "\n",
        "### Download and Install Ollama\n",
        "\n",
        "https://www.ollama.com/download\n",
        "\n",
        "### Select the Models\n",
        "\n",
        "https://www.ollama.com/library\n",
        "\n",
        "### Pull the model you want and run it in your terminal\n",
        "\n",
        "Example:\n",
        "\n",
        "```ollama pull llama3.1```\n",
        "\n",
        "```ollama run llama3.1```\n",
        "\n",
        "---\n",
        "### OPTIONAL. If you want to run your local Ollama models from the Internet (exemple: Colab)\n",
        "\n",
        "- Donwload and install ngrok\n",
        "\n",
        "- Sign-up on ngrok for your authtoken\n",
        "\n",
        "```ngrok config add-authtoken <token>```\n",
        "\n",
        "- Run ngrok forwarding the port to the Internet\n",
        "\n",
        "```ngrok http 11434 --host-header=\"localhost:11434\"```"
      ],
      "metadata": {
        "id": "OPeGrSjzH86I"
      }
    }
  ]
}